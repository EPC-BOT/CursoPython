{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSokqlVX30qViy+6fMfhdH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EPC-BOT/CursoPython/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkoxYZ4PMsfa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "import pygame\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Inicializa o mixer de áudio\n",
        "pygame.mixer.init()\n",
        "\n",
        "# Carrega o arquivo de som\n",
        "pygame.mixer.music.load(\"sonscerrado.mp3\")\n",
        "\n",
        "# Pontos dos olhos e boca\n",
        "p_olho_esq = [385, 380, 387, 373, 362, 263]\n",
        "p_olho_dir = [160, 144, 158, 153, 33, 133]\n",
        "p_olhos = p_olho_esq + p_olho_dir\n",
        "p_boca = [82, 87, 13, 14, 312, 317, 78, 308]\n",
        "\n",
        "# Função EAR\n",
        "def calculo_ear(face, p_olho_dir, p_olho_esq):\n",
        "    try:\n",
        "        face = np.array([[coord.x, coord.y] for coord in face])\n",
        "        face_esq = face[p_olho_esq, :]\n",
        "        face_dir = face[p_olho_dir, :]\n",
        "\n",
        "        ear_esq = (np.linalg.norm(face_esq[0] - face_esq[1]) + np.linalg.norm(face_esq[2] - face_esq[3])) / (2 * (np.linalg.norm(face_esq[4] - face_esq[5])))\n",
        "        ear_dir = (np.linalg.norm(face_dir[0] - face_dir[1]) + np.linalg.norm(face_dir[2] - face_dir[3])) / (2 * (np.linalg.norm(face_dir[4] - face_dir[5])))\n",
        "\n",
        "    except:\n",
        "        ear_esq = 0.0\n",
        "        ear_dir = 0.0\n",
        "    media_ear = (ear_esq + ear_dir) / 2\n",
        "    return media_ear\n",
        "\n",
        "# Função MAR\n",
        "def calculo_mar(face, p_boca):\n",
        "    try:\n",
        "        face = np.array([[coord.x, coord.y] for coord in face])\n",
        "        face_boca = face[p_boca, :]\n",
        "\n",
        "        mar = (np.linalg.norm(face_boca[0] - face_boca[1]) + np.linalg.norm(face_boca[2] - face_boca[3]) + np.linalg.norm(face_boca[4] - face_boca[5])) / (2 * (np.linalg.norm(face_boca[6] - face_boca[7])))\n",
        "    except:\n",
        "        mar = 0.0\n",
        "    return mar\n",
        "\n",
        "# Limiares\n",
        "ear_limiar = 0.27\n",
        "mar_limiar = 0.1  # Limiar para boca aberta\n",
        "dormindo = 0\n",
        "\n",
        "# Inicializa a câmera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# Estado do som\n",
        "som_tocando = False\n",
        "\n",
        "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as facemesh:\n",
        "    while cap.isOpened():\n",
        "        sucesso, frame = cap.read()\n",
        "        if not sucesso:\n",
        "            print('Ignorando o frame vazio da câmera.')\n",
        "            continue\n",
        "\n",
        "        comprimento, largura, _ = frame.shape\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        saida_facemesh = facemesh.process(frame)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        if saida_facemesh.multi_face_landmarks:\n",
        "            print(\"Rosto detectado\")\n",
        "        else:\n",
        "            print(\"Nenhum rosto detectado\")\n",
        "\n",
        "        try:\n",
        "            for face_landmarks in saida_facemesh.multi_face_landmarks:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    frame,\n",
        "                    face_landmarks,\n",
        "                    mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 102, 102), thickness=1, circle_radius=1),\n",
        "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(102, 204, 0), thickness=1, circle_radius=1)\n",
        "                )\n",
        "\n",
        "                face = face_landmarks.landmark\n",
        "\n",
        "                for id_coord, coord_xyz in enumerate(face):\n",
        "                    if id_coord in p_olhos:\n",
        "                        coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, largura, comprimento)\n",
        "                        cv2.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
        "                    if id_coord in p_boca:\n",
        "                        coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, largura, comprimento)\n",
        "                        cv2.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
        "\n",
        "                # Chamada do EAR e print\n",
        "                ear = calculo_ear(face, p_olho_dir, p_olho_esq)\n",
        "                cv2.rectangle(frame, (0, 1), (290, 140), (58, 58, 55), -1)\n",
        "                cv2.putText(frame, f\"EAR: {round(ear, 2)}\", (1, 24),\n",
        "                            cv2.FONT_HERSHEY_DUPLEX,\n",
        "                            0.9, (255, 255, 255), 2)\n",
        "\n",
        "                # Chamada do MAR e print\n",
        "                mar = calculo_mar(face, p_boca)\n",
        "                cv2.putText(frame, f\"MAR: {round(mar, 2)} {'abertos' if mar >= mar_limiar else 'fechados'}\", (1, 50),\n",
        "                            cv2.FONT_HERSHEY_DUPLEX,\n",
        "                            0.9, (255, 255, 255), 2)\n",
        "\n",
        "                # Verificação para tocar/pausar o som baseado no MAR\n",
        "                if mar >= mar_limiar:  # Se a boca estiver aberta\n",
        "                    if not som_tocando:\n",
        "                        pygame.mixer.music.play(-1)  # Toca continuamente\n",
        "                        som_tocando = True  # Atualiza o estado para som tocando\n",
        "                else:  # Se a boca estiver fechada\n",
        "                    if som_tocando:\n",
        "                        pygame.mixer.music.stop()  # Para o som\n",
        "                        som_tocando = False  # Atualiza o estado para som parado\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Erro:\", e)\n",
        "\n",
        "        finally:\n",
        "            print(\"Processamento concluído\")\n",
        "\n",
        "        cv2.imshow('Camera', frame)\n",
        "\n",
        "        # Se pressionar 'q', o programa termina\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ]
}